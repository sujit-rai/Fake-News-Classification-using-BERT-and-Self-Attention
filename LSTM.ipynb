{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bcgiZgPHbJN0","colab_type":"code","outputId":"efd09fdb-dc39-4046-e91a-1ec751a9c7ab","executionInfo":{"status":"ok","timestamp":1564990372067,"user_tz":-330,"elapsed":5795,"user":{"displayName":"Sujit Rai","photoUrl":"","userId":"07331316107733932435"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z6JfUbkca-yP","colab_type":"code","outputId":"7d6b3f81-05ed-4c74-ac5e-2b0ef85d06d9","executionInfo":{"status":"ok","timestamp":1564991072163,"user_tz":-330,"elapsed":705882,"user":{"displayName":"Sujit Rai","photoUrl":"","userId":"07331316107733932435"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","n_labels = 6\n","\n","GDFS_path = \"/content/drive/My Drive/Colab Notebooks/fake_lstm/\"\n","\n","def sample(arr, labels, seq):\n","\tsample_sentences = []\n","\tsample_labels = []\n","\tfor i in range(len(arr)):\n","\t\ttokens = len(arr[i])\n","\t\tif tokens < seq:\n","\t\t\tinst = np.array(arr[i],dtype=np.float32)\n","\t\t\tzeros = np.ones((seq-tokens, 60))\n","\t\t\tinst = np.concatenate([inst, zeros], axis=0)\n","\t\t\tsample_sentences.append(inst)\n","\t\t\tsample_labels.append(labels[i])\n","\tsample_sentences = np.array(sample_sentences, dtype=np.float32)\n","\tsample_labels = np.array(sample_labels, dtype=np.int32)\n","\tonehot_labels = np.eye(n_labels)[sample_labels]\n","\tprint(sample_sentences.shape)\n","\tprint(onehot_labels.shape)    \n","\treturn np.nan_to_num(sample_sentences,copy=False), onehot_labels\n","\n","\n","def load_data(type):\n","\ttrain_sentences = np.load(GDFS_path+\"train_multi_glove_m.npy\", allow_pickle=True)\n","\ttrain_labels = np.load(GDFS_path+\"train_\"+type+\"_labels_m.npy\", allow_pickle=True)\n","\tval_sentences = np.load(GDFS_path+\"val_\"+type+\"_glove_m.npy\", allow_pickle=True)\n","\tval_labels = np.load(GDFS_path+\"val_\"+type+\"_labels_m.npy\", allow_pickle=True)\n","\ttest_sentences = np.load(GDFS_path+\"test_\"+type+\"_glove_m.npy\", allow_pickle=True)\n","\ttest_labels = np.load(GDFS_path+\"test_\"+type+\"_labels_m.npy\", allow_pickle=True)\n","\treturn train_sentences, train_labels, test_sentences, test_labels, val_sentences, val_labels\n","\n","\n","train_sentences, train_labels, test_sentences, test_labels, val_sentences, val_labels = load_data(\"binary\")\n","\n","\n","\n","\n","seq_length = 200\n","\n","epochs = 10\n","\n","batch_size = 32\n","\n","batches = train_labels.shape[0]//batch_size\n","\n","test_batches = test_labels.shape[0]//batch_size\n","\n","val_batches = val_labels.shape[0]//batch_size\n","\n","\n","train_vects, train_labels = sample(train_sentences, train_labels, seq_length)\n","test_vects, test_labels = sample(test_sentences, test_labels, seq_length)\n","val_vects, val_labels = sample(val_sentences, val_labels, seq_length)\n","\n","\n","\n","\n","x = tf.placeholder(tf.float32, [None, seq_length, 60], name=\"x\")\n","y = tf.placeholder(tf.float32, [None, n_labels], name=\"y\")\n","\n","inpt = tf.transpose(x, [1,0,2])\n","\n","\n","def lstm_cell(lstm_size, keep_prob):\n","    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n","    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n","    return lstm\n","\n","cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(128, 0.75) for _ in range(4)])\n","\n","state = cell.zero_state(batch_size, tf.float32)\n","\n","outputs, final_state = tf.nn.dynamic_rnn(cell, inpt, initial_state=state, time_major=True)\n","\n","output_final = tf.squeeze(tf.slice(outputs, [seq_length-1,0,0] , [1,-1,-1]))\n","\n","fc1 = tf.layers.dense(output_final, units=256, activation=tf.nn.leaky_relu)\n","\n","logit = tf.squeeze(tf.layers.dense(fc1, units=n_labels, activation=None))\n","\n","loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=y))\n","\n","op = tf.train.AdamOptimizer(0.0001).minimize(loss)\n","\n","pred = tf.argmax(tf.nn.sigmoid(logit), axis=1)\n","\n","actual = tf.argmax(y, axis=1)\n","\n","acc = tf.reduce_mean(tf.to_float(tf.equal(pred, actual)))\n","\n","\n","\n","saver = tf.train.Saver()\n","\n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  val_accs = 0\n","  for ep in range(epochs):\n","    accs = []\n","    lss = []\n","\n","    for batch in range(batches//2):\n","      random_indexes = np.random.choice(train_labels.shape[0], batch_size)\n","      x_batch = train_vects[random_indexes]\n","      y_batch = train_labels[random_indexes]\n","      fd = {x: x_batch, y: y_batch}\n","      _, ls, ac = sess.run([op, loss, acc], fd)\n","      accs.append(ac)\n","      lss.append(ls)\n","    print(\"epoch : \", ep, \", loss : \", np.mean(lss), \", acc : \", np.mean(accs))\n","    accs = []\n","    lss = []\n","    for batch in range(val_batches//2):\n","      random_indexes = np.random.choice(val_labels.shape[0], batch_size)\n","      x_batch = val_vects[random_indexes]\n","      y_batch = val_labels[random_indexes]\n","      fd = {x: x_batch, y: y_batch}\n","      ls, ac = sess.run([loss, acc], fd)\n","      accs.append(ac)\n","      lss.append(ls)\n","    print(\"val set | loss : \", np.mean(lss), \", acc : \", np.mean(accs))\n","    if np.mean(accs) >= val_accs:\n","      saver.save(sess, \"./model_ckpt\")\n","      val_accs = np.mean(accs)\n","  accs = []\n","  saver.restore(sess, \"./model_ckpt\")\n","  print(\"saved modes val acc : \", val_accs)\n","  for batch in range(test_batches):\n","    random_indexes = np.random.choice(test_labels.shape[0], batch_size)\n","    x_batch = test_vects[random_indexes]\n","    y_batch = test_labels[random_indexes]\n","    fd = {x: x_batch, y: y_batch}\n","    ls, ac = sess.run([loss, acc], fd)\n","    accs.append(ac)\n","  print(\"test set | acc : \", np.mean(accs))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(10143, 200, 60)\n","(10143, 6)\n","(1248, 200, 60)\n","(1248, 6)\n","(1274, 200, 60)\n","(1274, 6)\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0805 07:33:09.457991 140504847247232 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0805 07:33:09.459727 140504847247232 deprecation.py:323] From <ipython-input-2-bd4c69e63927>:69: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","W0805 07:33:09.477757 140504847247232 deprecation.py:323] From <ipython-input-2-bd4c69e63927>:73: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","W0805 07:33:09.528147 140504847247232 deprecation.py:323] From <ipython-input-2-bd4c69e63927>:77: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W0805 07:33:09.891707 140504847247232 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0805 07:33:09.908434 140504847247232 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0805 07:33:10.608940 140504847247232 deprecation.py:323] From <ipython-input-2-bd4c69e63927>:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","W0805 07:33:10.948216 140504847247232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0805 07:33:11.941125 140504847247232 deprecation.py:323] From <ipython-input-2-bd4c69e63927>:93: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch :  0 , loss :  0.29002124 , acc :  0.54472655\n","val set | loss :  0.23564076 , acc :  0.53125\n","epoch :  1 , loss :  0.22971621 , acc :  0.5638672\n","val set | loss :  0.23207767 , acc :  0.5625\n","epoch :  2 , loss :  0.23077154 , acc :  0.5466797\n","val set | loss :  0.23058537 , acc :  0.5359375\n","epoch :  3 , loss :  0.22988883 , acc :  0.55507815\n","val set | loss :  0.23338473 , acc :  0.496875\n","epoch :  4 , loss :  0.2289855 , acc :  0.5625\n","val set | loss :  0.23230596 , acc :  0.525\n","epoch :  5 , loss :  0.23018412 , acc :  0.5457031\n","val set | loss :  0.23378846 , acc :  0.484375\n","epoch :  6 , loss :  0.23047373 , acc :  0.5408203\n","val set | loss :  0.23083112 , acc :  0.5234375\n","epoch :  7 , loss :  0.22865196 , acc :  0.5666016\n","val set | loss :  0.23173526 , acc :  0.5109375\n","epoch :  8 , loss :  0.22898726 , acc :  0.56171876\n","val set | loss :  0.23175402 , acc :  0.509375\n","epoch :  9 , loss :  0.22786012 , acc :  0.5740234\n"],"name":"stdout"},{"output_type":"stream","text":["W0805 07:44:24.145426 140504847247232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["val set | loss :  0.23445508 , acc :  0.5421875\n","saved modes val acc :  0.5625\n","test set | acc :  0.5608974\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2JnoVGPhccdt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}